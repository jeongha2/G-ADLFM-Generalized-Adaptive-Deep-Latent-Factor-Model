{"cells":[{"cell_type":"code","execution_count":null,"id":"66fe8759","metadata":{"id":"66fe8759"},"outputs":[],"source":["import tensorflow as tf\n","import random\n","import os\n","import pickle\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","source":["def seed_everything(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything(42)"],"metadata":{"id":"t4v3_H8sTDe-"},"id":"t4v3_H8sTDe-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kGpvld8TDty","executionInfo":{"status":"ok","timestamp":1654366160522,"user_tz":-540,"elapsed":28402,"user":{"displayName":"김정하","userId":"03202548441796445148"}},"outputId":"69a6e5f0-99c1-4ea9-a570-af5aa4d12363"},"id":"6kGpvld8TDty","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"0d4db6b3","metadata":{"id":"0d4db6b3"},"outputs":[],"source":["with open(\"beauty_4/train_id_data.pickle\",\"rb\") as fr:\n","    train_data = pickle.load(fr)\n","\n","with open(\"beauty_4/valid_id_data.pickle\",\"rb\") as fr:\n","    valid_data = pickle.load(fr)\n","    \n","with open(\"beauty_4/test_id_data.pickle\",\"rb\") as fr:\n","    test_data = pickle.load(fr)"]},{"cell_type":"code","execution_count":null,"id":"00822c00","metadata":{"id":"00822c00"},"outputs":[],"source":["with open(\"beauty_4/train_target.pickle\",\"rb\") as fr:\n","    train_target = pickle.load(fr)\n","    \n","with open(\"beauty_4/valid_target.pickle\",\"rb\") as fr:\n","    valid_target = pickle.load(fr)\n","    \n","with open(\"beauty_4/test_target.pickle\",\"rb\") as fr:\n","    test_target = pickle.load(fr)"]},{"cell_type":"code","source":["# ID\n","train_data[0] = tf.convert_to_tensor(train_data[0], dtype=tf.float32)\n","train_data[1] = tf.convert_to_tensor(train_data[1], dtype=tf.float32)"],"metadata":{"id":"kTNg2lZu20Ec"},"id":"kTNg2lZu20Ec","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"4d1e20e3","metadata":{"id":"4d1e20e3"},"source":["## Model"]},{"cell_type":"code","source":["!pip install keras_self_attention"],"metadata":{"id":"F7T184-Vh9mU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654366175899,"user_tz":-540,"elapsed":4185,"user":{"displayName":"김정하","userId":"03202548441796445148"}},"outputId":"99596145-6ecd-4f9c-ca3d-4a453899c12c"},"id":"F7T184-Vh9mU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_self_attention\n","  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.21.6)\n","Building wheels for collected packages: keras-self-attention\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=1bb02b723b35b02e007c2617472bdcbdc79ca3a71fd831b82210098a5a3ef4f8\n","  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n","Successfully built keras-self-attention\n","Installing collected packages: keras-self-attention\n","Successfully installed keras-self-attention-0.51.0\n"]}]},{"cell_type":"code","execution_count":null,"id":"2b3f4423","metadata":{"id":"2b3f4423"},"outputs":[],"source":["from tensorflow import keras\n","from keras.layers import Input, Embedding, LSTM, Dense, Lambda, Multiply, Bidirectional, Flatten\n","from keras_self_attention import SeqSelfAttention\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.pooling import MaxPool1D\n","from keras.models import Model\n","from keras.layers.wrappers import TimeDistributed\n","import numpy as np\n","import keras.backend as K\n","from random import randint\n","\n","import os\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","description_num = 4\n","#current_path ='data/'\n","#local_path = 'data/'"]},{"cell_type":"code","execution_count":null,"id":"e8d0126b","metadata":{"id":"e8d0126b"},"outputs":[],"source":["# set parameters:\n","V = 249274 \n","embedding_dim = 50\n","max_len = 1 \n","filters_num = 64\n","kernel_size = 3"]},{"cell_type":"code","execution_count":null,"id":"3a73a9e4","metadata":{"id":"3a73a9e4"},"outputs":[],"source":["input_1 = Input(shape=(description_num, max_len))\n","input_2 = Input(shape=(max_len,))\n","embedding = Embedding(input_dim=V,\n","                      output_dim=embedding_dim,\n","                      input_length=max_len)\n","self_att = SeqSelfAttention(attention_activation='sigmoid')\n","conv1d = Conv1D(filters=filters_num,\n","                kernel_size=kernel_size,\n","                activation='relu',\n","                padding='same')\n","maxpool1d = MaxPool1D(max_len)\n","dense = Dense(15)\n","\n","input_vector = TimeDistributed(embedding)(input_1)\n","validation_vector = embedding(input_2)\n","\n","selfatt_vector = TimeDistributed(self_att)(input_vector)\n","validation_selfatt = self_att(validation_vector)\n","\n","convolutional_vector = TimeDistributed(conv1d)(selfatt_vector)\n","validation_conv = conv1d(validation_selfatt)\n","\n","maxpooling_vector = TimeDistributed(maxpool1d)(convolutional_vector)\n","validation_maxpooling = maxpool1d(validation_conv)\n","\n","middle_output = TimeDistributed(dense)(maxpooling_vector)\n","middle_validation = dense(validation_maxpooling)"]},{"cell_type":"code","execution_count":null,"id":"c7660355","metadata":{"id":"c7660355"},"outputs":[],"source":["def change_dim_1(X):\n","    return K.squeeze(X, 1)\n","\n","def change_dim_2(X):\n","    return K.squeeze(X, 2)\n","\n","def repeat(X):\n","    return K.repeat_elements(X, description_num, 1)\n","\n","def repeat1(X):\n","    return K.repeat_elements(X, 15, 2)\n","\n","def repeat2(X):\n","    return K.repeat_elements(X, description_num, 1)\n","\n","def dot(X, Y):\n","    return K.dot(X, Y)\n","\n","def sum_item(X):\n","    return K.sum(X, axis=2)\n","\n","def sqrt_item(X):\n","    return K.sqrt(X)\n","\n","def cal_denominator(X):\n","    return 1/(X)\n","\n","def expand_item(X):\n","    return K.expand_dims(X, 2)\n","\n","def expand_rate(X):\n","    return K.expand_dims(X, 1)\n","\n","def sum_user(X):\n","    return K.sum(X, 1)\n","\n","def sum_rate(X):\n","    return K.sum(X, 1)\n","\n","def single_exp(X):\n","    return K.exp(X)\n","\n","def sum_exp_denominator(X):\n","    return 1/(K.sum(K.exp(X), 1))"]},{"cell_type":"code","execution_count":null,"id":"6c00b2cf","metadata":{"scrolled":false,"id":"6c00b2cf"},"outputs":[],"source":["middle_output_final = Lambda(change_dim_2)(middle_output)#?*10*15\n","middle_validation_final = Lambda(repeat)(middle_validation)#?*10*15\n","molecule = Multiply()([middle_output_final, middle_validation_final])\n","molecule = Lambda(sum_item)(molecule)\n","\n","denominator1 = Multiply()([middle_output_final, middle_output_final])\n","denominator1 = Lambda(sum_item)(denominator1)\n","denominator1 = Lambda(sqrt_item)(denominator1)\n","\n","denominator2 = Multiply()([middle_validation_final, middle_validation_final])\n","denominator2 = Lambda(sum_item)(denominator2)\n","denominator2 = Lambda(sqrt_item)(denominator2)\n","\n","\n","denominator = Multiply()([denominator1, denominator2])\n","denominator = Lambda(cal_denominator)(denominator)\n","\n","similarity = Multiply()([molecule, denominator])\n","similarity = Lambda(expand_item)(similarity)\n","similarity = Lambda(repeat1)(similarity)\n","\n","\n","user = Multiply()([similarity, middle_output_final])\n","user = Lambda(sum_user)(user)\n","\n","\n","item = Lambda(change_dim_1)(middle_validation)\n","\n","\n","rate_hat = Multiply()([user, item])\n","rate_hat = Lambda(sum_rate)(rate_hat)\n","rate_hat = Lambda(expand_rate)(rate_hat)"]},{"cell_type":"code","execution_count":null,"id":"c3c0847b","metadata":{"id":"c3c0847b"},"outputs":[],"source":["model = Model(inputs=[input_1, input_2], outputs=rate_hat)\n","model.compile(optimizer='adam', loss='mae', metrics=['mse', 'mae', 'mape'])"]},{"cell_type":"code","execution_count":null,"id":"76e1f28c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76e1f28c","executionInfo":{"status":"ok","timestamp":1654366177305,"user_tz":-540,"elapsed":354,"user":{"displayName":"김정하","userId":"03202548441796445148"}},"outputId":"1e108b78-1410-448e-a5cf-d8358e6427d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 4, 1)]       0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 1)]          0           []                               \n","                                                                                                  \n"," time_distributed (TimeDistribu  (None, 4, 1, 50)    12463700    ['input_1[0][0]']                \n"," ted)                                                                                             \n","                                                                                                  \n"," embedding (Embedding)          (None, 1, 50)        12463700    ['input_2[0][0]']                \n","                                                                                                  \n"," time_distributed_1 (TimeDistri  (None, 4, 1, 50)    3265        ['time_distributed[0][0]']       \n"," buted)                                                                                           \n","                                                                                                  \n"," seq_self_attention (SeqSelfAtt  (None, 1, 50)       3265        ['embedding[0][0]']              \n"," ention)                                                                                          \n","                                                                                                  \n"," time_distributed_2 (TimeDistri  (None, 4, 1, 64)    9664        ['time_distributed_1[0][0]']     \n"," buted)                                                                                           \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 1, 64)        9664        ['seq_self_attention[0][0]']     \n","                                                                                                  \n"," time_distributed_3 (TimeDistri  (None, 4, 1, 64)    0           ['time_distributed_2[0][0]']     \n"," buted)                                                                                           \n","                                                                                                  \n"," max_pooling1d (MaxPooling1D)   (None, 1, 64)        0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," time_distributed_4 (TimeDistri  (None, 4, 1, 15)    975         ['time_distributed_3[0][0]']     \n"," buted)                                                                                           \n","                                                                                                  \n"," dense (Dense)                  (None, 1, 15)        975         ['max_pooling1d[0][0]']          \n","                                                                                                  \n"," lambda (Lambda)                (None, 4, 15)        0           ['time_distributed_4[0][0]']     \n","                                                                                                  \n"," lambda_1 (Lambda)              (None, 4, 15)        0           ['dense[0][0]']                  \n","                                                                                                  \n"," multiply_1 (Multiply)          (None, 4, 15)        0           ['lambda[0][0]',                 \n","                                                                  'lambda[0][0]']                 \n","                                                                                                  \n"," multiply_2 (Multiply)          (None, 4, 15)        0           ['lambda_1[0][0]',               \n","                                                                  'lambda_1[0][0]']               \n","                                                                                                  \n"," lambda_3 (Lambda)              (None, 4)            0           ['multiply_1[0][0]']             \n","                                                                                                  \n"," lambda_5 (Lambda)              (None, 4)            0           ['multiply_2[0][0]']             \n","                                                                                                  \n"," lambda_4 (Lambda)              (None, 4)            0           ['lambda_3[0][0]']               \n","                                                                                                  \n"," lambda_6 (Lambda)              (None, 4)            0           ['lambda_5[0][0]']               \n","                                                                                                  \n"," multiply (Multiply)            (None, 4, 15)        0           ['lambda[0][0]',                 \n","                                                                  'lambda_1[0][0]']               \n","                                                                                                  \n"," multiply_3 (Multiply)          (None, 4)            0           ['lambda_4[0][0]',               \n","                                                                  'lambda_6[0][0]']               \n","                                                                                                  \n"," lambda_2 (Lambda)              (None, 4)            0           ['multiply[0][0]']               \n","                                                                                                  \n"," lambda_7 (Lambda)              (None, 4)            0           ['multiply_3[0][0]']             \n","                                                                                                  \n"," multiply_4 (Multiply)          (None, 4)            0           ['lambda_2[0][0]',               \n","                                                                  'lambda_7[0][0]']               \n","                                                                                                  \n"," lambda_8 (Lambda)              (None, 4, 1)         0           ['multiply_4[0][0]']             \n","                                                                                                  \n"," lambda_9 (Lambda)              (None, 4, 15)        0           ['lambda_8[0][0]']               \n","                                                                                                  \n"," multiply_5 (Multiply)          (None, 4, 15)        0           ['lambda_9[0][0]',               \n","                                                                  'lambda[0][0]']                 \n","                                                                                                  \n"," lambda_10 (Lambda)             (None, 15)           0           ['multiply_5[0][0]']             \n","                                                                                                  \n"," lambda_11 (Lambda)             (None, 15)           0           ['dense[0][0]']                  \n","                                                                                                  \n"," multiply_6 (Multiply)          (None, 15)           0           ['lambda_10[0][0]',              \n","                                                                  'lambda_11[0][0]']              \n","                                                                                                  \n"," lambda_12 (Lambda)             (None,)              0           ['multiply_6[0][0]']             \n","                                                                                                  \n"," lambda_13 (Lambda)             (None, 1)            0           ['lambda_12[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 12,477,604\n","Trainable params: 12,477,604\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"id":"441d8dc5","metadata":{"id":"441d8dc5","outputId":"6c12bef9-b1b1-4168-994c-fdd929633410","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654366297821,"user_tz":-540,"elapsed":120529,"user":{"displayName":"김정하","userId":"03202548441796445148"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","256/256 [==============================] - 18s 16ms/step - loss: 1.2849 - mse: 4.0278 - mae: 1.2849 - mape: 51.8442 - val_loss: 0.8065 - val_mse: 2.1102 - val_mae: 0.8065 - val_mape: 46.6361\n","Epoch 2/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.7803 - mse: 1.8920 - mae: 0.7803 - mape: 43.7515 - val_loss: 0.8323 - val_mse: 1.9101 - val_mae: 0.8323 - val_mape: 45.0961\n","Epoch 3/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.7098 - mse: 1.5215 - mae: 0.7098 - mape: 38.3416 - val_loss: 0.8586 - val_mse: 1.8497 - val_mae: 0.8586 - val_mape: 44.4562\n","Epoch 4/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.6624 - mse: 1.3392 - mae: 0.6624 - mape: 35.1315 - val_loss: 0.8690 - val_mse: 1.8628 - val_mae: 0.8690 - val_mape: 44.4004\n","Epoch 5/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.6264 - mse: 1.1910 - mae: 0.6264 - mape: 32.5767 - val_loss: 0.8908 - val_mse: 1.8284 - val_mae: 0.8908 - val_mape: 44.0910\n","Epoch 6/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.5914 - mse: 1.0471 - mae: 0.5914 - mape: 30.1787 - val_loss: 0.9085 - val_mse: 1.7921 - val_mae: 0.9085 - val_mape: 43.7246\n","Epoch 7/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.5531 - mse: 0.9137 - mae: 0.5531 - mape: 27.8387 - val_loss: 0.9192 - val_mse: 1.8111 - val_mae: 0.9192 - val_mape: 43.8334\n","Epoch 8/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.5171 - mse: 0.7985 - mae: 0.5171 - mape: 25.6749 - val_loss: 0.9454 - val_mse: 1.8309 - val_mae: 0.9454 - val_mape: 43.7084\n","Epoch 9/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.4856 - mse: 0.7027 - mae: 0.4856 - mape: 23.7876 - val_loss: 0.9583 - val_mse: 1.8557 - val_mae: 0.9583 - val_mape: 43.8114\n","Epoch 10/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.4550 - mse: 0.6269 - mae: 0.4550 - mape: 22.1861 - val_loss: 0.9575 - val_mse: 1.8847 - val_mae: 0.9575 - val_mape: 44.1815\n","Epoch 11/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.4297 - mse: 0.5665 - mae: 0.4297 - mape: 20.8250 - val_loss: 0.9697 - val_mse: 1.8484 - val_mae: 0.9697 - val_mape: 43.8433\n","Epoch 12/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.4075 - mse: 0.5177 - mae: 0.4075 - mape: 19.6825 - val_loss: 0.9820 - val_mse: 1.8596 - val_mae: 0.9820 - val_mape: 43.7510\n","Epoch 13/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.3901 - mse: 0.4790 - mae: 0.3901 - mape: 18.7635 - val_loss: 0.9956 - val_mse: 1.8750 - val_mae: 0.9956 - val_mape: 43.7552\n","Epoch 14/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.3740 - mse: 0.4460 - mae: 0.3740 - mape: 17.9647 - val_loss: 0.9971 - val_mse: 1.8887 - val_mae: 0.9971 - val_mape: 43.8819\n","Epoch 15/30\n","256/256 [==============================] - 4s 15ms/step - loss: 0.3595 - mse: 0.4179 - mae: 0.3595 - mape: 17.2441 - val_loss: 1.0001 - val_mse: 1.8765 - val_mae: 1.0001 - val_mape: 43.8002\n","Epoch 16/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.3485 - mse: 0.3958 - mae: 0.3485 - mape: 16.6835 - val_loss: 1.0138 - val_mse: 1.9094 - val_mae: 1.0138 - val_mape: 43.9163\n","Epoch 17/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.3386 - mse: 0.3763 - mae: 0.3386 - mape: 16.1976 - val_loss: 1.0157 - val_mse: 1.8866 - val_mae: 1.0157 - val_mape: 43.7484\n","Epoch 18/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.3276 - mse: 0.3584 - mae: 0.3276 - mape: 15.6884 - val_loss: 1.0139 - val_mse: 1.9203 - val_mae: 1.0139 - val_mape: 44.0831\n","Epoch 19/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.3204 - mse: 0.3437 - mae: 0.3204 - mape: 15.3187 - val_loss: 1.0281 - val_mse: 1.8962 - val_mae: 1.0281 - val_mape: 43.6627\n","Epoch 20/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.3120 - mse: 0.3311 - mae: 0.3120 - mape: 14.9524 - val_loss: 1.0254 - val_mse: 1.9019 - val_mae: 1.0254 - val_mape: 43.7977\n","Epoch 21/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.3044 - mse: 0.3189 - mae: 0.3044 - mape: 14.6246 - val_loss: 1.0203 - val_mse: 1.9176 - val_mae: 1.0203 - val_mape: 44.0479\n","Epoch 22/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.2982 - mse: 0.3083 - mae: 0.2982 - mape: 14.3128 - val_loss: 1.0224 - val_mse: 1.9416 - val_mae: 1.0224 - val_mape: 44.2668\n","Epoch 23/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.2932 - mse: 0.2994 - mae: 0.2932 - mape: 14.0757 - val_loss: 1.0320 - val_mse: 1.9090 - val_mae: 1.0320 - val_mape: 43.7785\n","Epoch 24/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.2879 - mse: 0.2906 - mae: 0.2879 - mape: 13.8286 - val_loss: 1.0287 - val_mse: 1.9511 - val_mae: 1.0287 - val_mape: 44.3089\n","Epoch 25/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.2834 - mse: 0.2835 - mae: 0.2834 - mape: 13.6277 - val_loss: 1.0340 - val_mse: 1.9467 - val_mae: 1.0340 - val_mape: 44.1648\n","Epoch 26/30\n","256/256 [==============================] - 4s 14ms/step - loss: 0.2782 - mse: 0.2764 - mae: 0.2782 - mape: 13.4287 - val_loss: 1.0441 - val_mse: 1.9442 - val_mae: 1.0441 - val_mape: 43.9223\n","Epoch 27/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.2743 - mse: 0.2697 - mae: 0.2743 - mape: 13.2337 - val_loss: 1.0467 - val_mse: 1.9135 - val_mae: 1.0467 - val_mape: 43.6422\n","Epoch 28/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.2703 - mse: 0.2639 - mae: 0.2703 - mape: 13.0566 - val_loss: 1.0353 - val_mse: 1.9473 - val_mae: 1.0353 - val_mape: 44.1129\n","Epoch 29/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.2661 - mse: 0.2579 - mae: 0.2661 - mape: 12.8789 - val_loss: 1.0381 - val_mse: 1.9567 - val_mae: 1.0381 - val_mape: 44.2406\n","Epoch 30/30\n","256/256 [==============================] - 3s 14ms/step - loss: 0.2630 - mse: 0.2532 - mae: 0.2630 - mape: 12.7438 - val_loss: 1.0451 - val_mse: 1.9478 - val_mae: 1.0451 - val_mape: 43.9968\n"]}],"source":["hist = model.fit(train_data, train_target,\n","                 validation_data=(valid_data, valid_target),\n","                 steps_per_epoch=256,\n","                 validation_steps=256,\n","                 epochs=30,\n","                 verbose=1)"]},{"cell_type":"code","execution_count":null,"id":"f3cd8771","metadata":{"id":"f3cd8771","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654366308297,"user_tz":-540,"elapsed":10484,"user":{"displayName":"김정하","userId":"03202548441796445148"}},"outputId":"efb6b71a-e283-4924-e9d1-3bf8d6d98a72"},"outputs":[{"output_type":"stream","name":"stdout","text":["2457/2500 [============================>.] - ETA: 0s - loss: 1.0537 - mse: 1.9750 - mae: 1.0537 - mape: 44.5049WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2500 batches). You may need to use the repeat() function when building your dataset.\n","2500/2500 [==============================] - 8s 3ms/step - loss: 1.0535 - mse: 1.9744 - mae: 1.0535 - mape: 44.4922\n","[1.0534920692443848, 1.974400281906128, 1.0534920692443848, 44.4921989440918]\n"]}],"source":["scores = model.evaluate(test_data, test_target, steps=2500)\n","print(scores)"]},{"cell_type":"code","execution_count":null,"id":"2981ce4f","metadata":{"id":"2981ce4f"},"outputs":[],"source":[""]}],"metadata":{"interpreter":{"hash":"88632544536f896c8f35d918b5e3583a50162ec118335e005391c3e813c5eb36"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"G-ADLFM_Self-attention.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}